<h1 class="text-h2-lightblue" style="box-sizing: border-box; margin-top: 20px; margin-bottom: 10px; font-size: 1.8em; font-family: Raleway; line-height: 1.1; color: #2c99ce;">Linear Perceptron</h1>
<div class="content" id="experiment-article-section-6-content" style="box-sizing: border-box; color: #333333; font-family: Raleway; font-size: 14px;">
<p style="box-sizing: border-box; margin: 0px 0px 10px; font-size: 16px;"><img src="http://cse20-iiith.vlabs.ac.in/exp3/images/perceptron.png" style="box-sizing: border-box; border: 0px; vertical-align: middle;" /><br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" />Data points are: Negative: (1, 1) (3, 1) (1, 4) Positive: (2, 4) (3, 3) (5, 1). Data points are classified as either +1 or -1. An unknown point is located at (2, 3)(Q 1-4).&nbsp;<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q1.&nbsp;</span>Assume that the points are examined in the order given above, starting with the negative points and then the positive points. Simulate one iteration of the perceptron algorithm with a learning rate of 0.5 and an initial weight vector of (-15 5 3).<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q2.&nbsp;</span>What is the equation of this line using the final weights from Question 1.<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q3.&nbsp;</span>Is this line a linear separator of the data?&nbsp;<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q4.&nbsp;</span>Using this line, what would be the predicted class of the unknown point (2, 3)? What is the margin of this point using the predicted class?<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q5.&nbsp;</span>For which kind of problem is the Adaline algorithm the best ?<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q6.&nbsp;</span>For which kind of problem is the Back propagation algorithm the best ?<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q7.&nbsp;</span>For which kind of problem is the Perceptron algorithm the best ?<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q8.&nbsp;</span>What would happen if the output function in a multi-layer perceptron would be omitted; i.e. if the output would simply be the weighted sum of all input signals? Why is that simpler output not normally used in MLPs although it would simplify and accelerate the calculations for the back propogation algorithm?&nbsp;<br style="box-sizing: border-box;" /><br style="box-sizing: border-box;" /><span style="box-sizing: border-box; font-weight: bold;">Q9.&nbsp;</span>Consider a classical xor example(two same inputs give 1 and different inputs give 0). How does the decision line look like? Is a simple, one-layer perceptron able to realize this function? Show by symbolic representations that the simple one-layer perceptron with two inputs x1 and x2 as well as a threshold (theta) cannot realize the xor function.&nbsp;</p>
</div>